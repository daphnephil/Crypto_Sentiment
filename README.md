# Crypto Sentiment Analysis Pipeline
This project aims to analyze cryptocurrency sentiment by collecting and analyzing historical data from the Bitstamp API for Bitcoin historical data and the Alternate.me Fear and Greed Index API for Bitcoin fear and greed index data. The pipeline is built to run on a Google Virtual Machine using Docker and utilizes Terraform and mage.ai for orchestration. Mage.ai is used for extracting data from the respective APIs and loading them into Google Cloud Storage and BigQuery. The data is then visualized using Looker.

## Table of Contents
* Introduction
* Setup
* Usage
* Contributing
* License

### Introduction
Cryptocurrencies have become increasingly popular as an investment option, but their value is highly volatile and influenced by various factors including market sentiment. Analyzing sentiment can provide valuable insights into market trends and help make informed decisions. This project aims to provide a comprehensive pipeline for analyzing cryptocurrency sentiment specifically focusing on Bitcoin.

### Project Structure
```
ðŸ“¦ 
â”œâ”€Â Crypto_Sentiment_Analysis.pdf
â”œâ”€Â Crypto_sentiment.svg
â”œâ”€Â README.md
â”œâ”€Â dbt
â”‚Â Â â”œâ”€Â .gitignore
â”‚Â Â â”œâ”€Â .gitkeep
â”‚Â Â â”œâ”€Â README.md
â”‚Â Â â”œâ”€Â analyses
â”‚Â Â â”‚Â Â â””â”€Â .gitkeep
â”‚Â Â â”œâ”€Â dbt_project.yml
â”‚Â Â â”œâ”€Â macros
â”‚Â Â â”‚Â Â â”œâ”€Â .gitkeep
â”‚Â Â â”‚Â Â â””â”€Â get_value_classification.sql
â”‚Â Â â”œâ”€Â models
â”‚Â Â â”‚Â Â â”œâ”€Â core
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â dim_crypto_sentiment.sql
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â fact_crypto_sentiment.sql
â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â schema.yml
â”‚Â Â â”‚Â Â â””â”€Â staging
â”‚Â Â â”‚Â Â Â Â Â â”œâ”€Â schema.yml
â”‚Â Â â”‚Â Â Â Â Â â”œâ”€Â stg_crypto_data_partitoned.sql
â”‚Â Â â”‚Â Â Â Â Â â””â”€Â stg_fng_data_partitoned_clustered.sql
â”‚Â Â â”œâ”€Â package-lock.yml
â”‚Â Â â”œâ”€Â packages.yml
â”‚Â Â â”œâ”€Â snapshots
â”‚Â Â â”‚Â Â â””â”€Â .gitkeep
â”‚Â Â â””â”€Â tests
â”‚Â Â Â Â Â â””â”€Â .gitkeep
â””â”€Â gcp
Â Â Â â”œâ”€Â .gitignore
Â Â Â â”œâ”€Â crypto_sentiment_pipeline
Â Â Â â”‚Â Â â”œâ”€Â __init__.py
Â Â Â â”‚Â Â â”œâ”€Â __pycache__
Â Â Â â”‚Â Â â”‚Â Â â””â”€Â __init__.cpython-310.pyc
Â Â Â â”‚Â Â â”œâ”€Â data_exporters
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __pycache__
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_crypto_data_to_bq.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_crypto_data_to_gcs.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_fng_data_to_bq.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_fng_data_to_gcs.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_titanic_clean.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â load_crypto_data_to_gcs.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_crypto_data_to_bq.py
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_crypto_data_to_gcs.py
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â export_fng_data_to_bq.py
Â Â Â â”‚Â Â â”‚Â Â â””â”€Â export_fng_data_to_gcs.py
Â Â Â â”‚Â Â â”œâ”€Â data_loaders
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __pycache__
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â creative_herald.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â gg.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_crypto_data_from_api.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_crypto_data_from_gcs.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_data_from_api.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_fng_data_from_api.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_fng_data_from_gcs.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_titanic.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â unstoppable_runesmith.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_crypto_data_from_api.py
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_crypto_data_from_gcs.py
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â load_fng_data_from_api.py
Â Â Â â”‚Â Â â”‚Â Â â””â”€Â load_fng_data_from_gcs.py
Â Â Â â”‚Â Â â”œâ”€Â metadata.yaml
Â Â Â â”‚Â Â â”œâ”€Â transformers
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
Â Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __pycache__
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â fill_in_missing_values.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â transform_crypto_data.cpython-310.pyc
Â Â Â â”‚Â Â â”‚Â Â â””â”€Â transform_crypto_data.py
Â Â Â â”‚Â Â â””â”€Â triggers.yaml
Â Â Â â”œâ”€Â db.tf
Â Â Â â”œâ”€Â fs.tf
Â Â Â â”œâ”€Â load_balancer.tf
Â Â Â â”œâ”€Â main.tf
Â Â Â â””â”€Â variables.tf
```
### Setup
To set up this project on google compute engine, follow these steps:
1. Set up google cloud by following this video description by [DataTalksClub](https://www.youtube.com/watch?v=ae-CV2KfoN0&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=14)
2. Install Dependencies:
* Anaconda
* Python
* Docker
* Terraform
* Google Cloud SDK --All these are explained in the video link above

3. Configure Google Cloud:
* Set up a Google Cloud project.
* Configure authentication for your Google Cloud project.
* Enable necessary APIs (BigQuery, Google Cloud Storage, etc.)
* Allow the following permissions for the project;
     - Artifact Registry Reader
     - Artifact Registry writer
     - Cloud Run Developer
     - Cloud SQL Admin
     - Service Account Token Creator

3. Clone this repository 

   ```
   git clone https://github.com/daphnephil/Crypto_Sentiment.git
   ```
4. Edit the files as instructed in this [mage doc](https://docs.mage.ai/production/deploying-to-cloud/gcp/setup)

### Usage
Once the setup is complete, you can run the pipeline to collect and analyze cryptocurrency sentiment data. Here's how to use the pipeline:
1. From the VM cd to Crypto_Sentiment/gcp
2. Run Terraform:
Use Terraform to provision resources on Google Cloud Platform.
```
terraform init
```
```
terraform plan
```
```
terraform apply
```
This builds the docker image for mage.ai in google cloud and creates the required resources defined in the terraform files.

2. Execute Mage.ai:
- Navigate to Cloud Run on GCP
- Click on the name of the service you created
- Copy the URL and paste on your browser.
Execute the crypto_sentiment pipeline on Mage to extract data from Bitstamp API and Alternate.me Fear and Greed Index API, and load it into Google Cloud Storage and BigQuery.
3. Destroy Resources Created
  ```
  terraform destroy
  ```

5. Transforming data with dbt
  - Connect dbt to bigquery.
  - Run
    ```
    dbt build
    ```
    This builds the fact and dimension models.
5. Visualize Data:
Use Looker or any other visualization tool to analyze and visualize the fact_crypto_sentiment_data.

### Contributing
Contributions are welcome! If you'd like to contribute to this project, please follow these steps:

1. Fork the repository.
2. Create a new branch (git checkout -b feature/improvement).
3. Make your changes.
4. Commit your changes (git commit -am 'Add new feature').
5. Push to the branch (git push origin feature/improvement).
6. Create a new Pull Request.
